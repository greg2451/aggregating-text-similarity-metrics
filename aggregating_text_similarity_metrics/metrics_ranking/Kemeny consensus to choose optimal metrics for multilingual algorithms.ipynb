{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6959a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010e26a",
   "metadata": {},
   "source": [
    "# Aggregating the results of different metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531ae0c",
   "metadata": {},
   "source": [
    "Some translation algorithms are multilingual by design. We focus on a specific case in which we are looking to evaluate the quality of traductions from a language to another, where these languages are not known. Knowing that the quality of metrics for NLG algorithms (in the sense of a correlation with human evaluation) depends on the languages that are translated, we would like to find a ranking of metrics that is robust to the different languages considered. \n",
    "We reverse the classical point of view of using fixed metrics to evaluate algorithms on different tasks. We can then use Kemeny consensus to evaluate the performance of metrics  on fixed tasks, with fixed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe78b37",
   "metadata": {},
   "source": [
    "## Kemeny consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610481f9",
   "metadata": {},
   "source": [
    "We use fixed datasets that are annotated and we apply different metrics to these datasets. We can the rank the metrics on these different datasets (same data for all metrics) according to the correlation of these metrics with human evaluation. Then we need to code a Kemeny ranking consensus to order the metrics according to their performances on different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f5f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_negative(n):\n",
    "    if n < 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Construction of a kendall distance function\n",
    "def kendall_distance(l1, l2):\n",
    "    if len(l1) != len(l2):\n",
    "        raise ValueError(\"Permutations does not have the same size\")\n",
    "    result = 0\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l1)):\n",
    "            result += is_negative((l1[i] - l1[j]) * (l2[i] - l2[j]))\n",
    "    normalization = len(l1) * (len(l1) - 1)\n",
    "    # normalization is made to make the distance be in [0,1]\n",
    "    return result / normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeeb52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(kendall_distance([0, 1, 2], [0, 1, 2]))\n",
    "print(kendall_distance([0, 1, 2], [2, 1, 0]))\n",
    "print(kendall_distance([0, 1, 2], [1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d44a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When having a matrix of different rankings of metrics on datasets based on their correlations with human evaluation\n",
    "def kemeny_consensus_step1(matrix, perm):\n",
    "    # matrix is an array in which matrix[i,j] is the ranking of metrics j on the dataset i\n",
    "    result = 0\n",
    "    for i in range(matrix.shape[0]):\n",
    "        result += kendall_distance(perm, matrix[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "def kemeny_consensus(matrix):\n",
    "    best_permutations = []\n",
    "    dist = kemeny_consensus_step1(matrix, matrix[0])\n",
    "    perm = permutations(matrix[0])\n",
    "    for permutation in tqdm(list(perm), \"Kemeny consensus\"):\n",
    "        dist_travail = kemeny_consensus_step1(matrix, permutation)\n",
    "        if dist_travail < dist:\n",
    "            best_permutations = []\n",
    "            best_permutations += [np.array(permutation)]\n",
    "            dist = dist_travail\n",
    "        elif dist == dist_travail:\n",
    "            best_permutations += [np.array(permutation)]\n",
    "    return best_permutations, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82d22d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333333333333333\n",
      "1.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array([[3, 2, 1, 0], [1, 2, 3, 0], [1, 3, 2, 0], [0, 1, 3, 2]])\n",
    "perm1 = [0, 1, 2, 3]\n",
    "print(kemeny_consensus_step1(matrix, perm1))\n",
    "perm2 = [3, 2, 1, 0]\n",
    "print(kemeny_consensus_step1(matrix, perm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bbc09d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kemeny consensus: 100%|██████████| 24/24 [00:00<00:00, 40281.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([array([1, 3, 2, 0]), array([1, 2, 3, 0])], 1.0)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemeny_consensus(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe070ef",
   "metadata": {},
   "source": [
    "## Improvement of Kemeny consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69cf74",
   "metadata": {},
   "source": [
    "All the rankings, given the different metrics have exactly the same weights. This might be a problem if we consider that some of the metrics are more relevant than others, or if some metrics are usually very close. So we can improve the Kemeny consensus by giving a higher weight to metrics that are more relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2b994fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_kemeny_consensus_step1(matrix, perm, weights):\n",
    "    # matrix is an array in which matrix[i,j] is the ranking of algorithm j at test i\n",
    "    # weights[i] is the weight associated to test i\n",
    "    result = 0\n",
    "    for i in range(matrix.shape[0]):\n",
    "        result += kendall_distance(perm, matrix[i]) * weights[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "def weighted_kemeny_consensus(matrix, weights):\n",
    "    best_permutations = []\n",
    "    dist = weighted_kemeny_consensus_step1(matrix, matrix[0], weights)\n",
    "    perm = permutations(matrix[0])\n",
    "    for permutation in tqdm(list(perm), \"Weighted kemeny consensus\"):\n",
    "        dist_travail = weighted_kemeny_consensus_step1(matrix, permutation, weights)\n",
    "        if dist_travail < dist:\n",
    "            best_permutations = []\n",
    "            best_permutations += [np.array(permutation)]\n",
    "            dist = dist_travail\n",
    "        elif dist == dist_travail:\n",
    "            best_permutations += [np.array(permutation)]\n",
    "    return best_permutations, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0070ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Weighted kemeny consensus: 100%|██████████| 24/24 [00:00<00:00, 39138.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([array([3, 2, 1, 0])], 0.16666666666666669)"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = [0.7, 0.1, 0.1, 0.1]\n",
    "weighted_kemeny_consensus(matrix, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b80eb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the correlations we can deduce\n",
    "def using_indexed_assignment(x):\n",
    "    result = np.empty(len(x), dtype=int)\n",
    "    x = -x\n",
    "    temp = x.argsort()\n",
    "    result[temp] = np.arange(len(x))\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_ranking(df):\n",
    "    ranking = df\n",
    "    for col in df.columns:\n",
    "        ranking[col] = using_indexed_assignment(df[col])\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c0f230",
   "metadata": {},
   "source": [
    "# Testing our methods on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b8b09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kendall_cs_en = (\n",
    "    pd.read_csv(\"data/corr_kendall_2016_cs-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_pearson_cs_en = (\n",
    "    pd.read_csv(\"data/corr_pearson_2016_cs-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_spearman_cs_en = (\n",
    "    pd.read_csv(\"data/corr_spearman_2016_cs-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_kendall_de_en = (\n",
    "    pd.read_csv(\"data/corr_kendall_2016_de-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_pearson_de_en = (\n",
    "    pd.read_csv(\"data/corr_pearson_2016_de-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_spearman_de_en = (\n",
    "    pd.read_csv(\"data/corr_spearman_2016_de-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_kendall_fi_en = (\n",
    "    pd.read_csv(\"data/corr_kendall_2016_fi-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_pearson_fi_en = (\n",
    "    pd.read_csv(\"data/corr_pearson_2016_fi-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_spearman_fi_en = (\n",
    "    pd.read_csv(\"data/corr_spearman_2016_fi-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_kendall_ro_en = (\n",
    "    pd.read_csv(\"data/corr_kendall_2016_ro-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_pearson_ro_en = (\n",
    "    pd.read_csv(\"data/corr_pearson_2016_ro-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_spearman_ro_en = (\n",
    "    pd.read_csv(\"data/corr_spearman_2016_ro-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_kendall_ru_en = (\n",
    "    pd.read_csv(\"data/corr_kendall_2016_ru-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_pearson_ru_en = (\n",
    "    pd.read_csv(\"data/corr_pearson_2016_ru-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")\n",
    "df_spearman_ru_en = (\n",
    "    pd.read_csv(\"data/corr_spearman_2016_ru-en.csv\")\n",
    "    .set_index(\"Unnamed: 0\")\n",
    "    .abs()\n",
    "    .drop([\"depth\", \"rouge2\", \"human_scores\"], axis=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b2bfe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_kendall_cs = get_ranking(\n",
    "    df_kendall_cs_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"kendall_cs\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_pearson_cs = get_ranking(\n",
    "    df_pearson_cs_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"pearson_cs\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_spearman_cs = get_ranking(\n",
    "    df_spearman_cs_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"spearman_cs\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_kendall_de = get_ranking(\n",
    "    df_kendall_de_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"kendall_de\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_pearson_de = get_ranking(\n",
    "    df_pearson_de_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"pearson_de\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_spearman_de = get_ranking(\n",
    "    df_spearman_de_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"spearman_de\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_kendall_fi = get_ranking(\n",
    "    df_kendall_fi_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"kendall_fi\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_pearson_fi = get_ranking(\n",
    "    df_pearson_fi_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"pearson_fi\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_spearman_fi = get_ranking(\n",
    "    df_spearman_fi_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"spearman_fi\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_kendall_ro = get_ranking(\n",
    "    df_kendall_ro_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"kendall_ro\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_pearson_ro = get_ranking(\n",
    "    df_pearson_ro_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"pearson_ro\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_spearman_ro = get_ranking(\n",
    "    df_spearman_ro_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"spearman_ro\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_kendall_ru = get_ranking(\n",
    "    df_kendall_ru_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"kendall_ru\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_pearson_ru = get_ranking(\n",
    "    df_pearson_ru_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"pearson_ru\"}\n",
    "    )\n",
    ").transpose()\n",
    "ranking_spearman_ru = get_ranking(\n",
    "    df_spearman_ru_en.loc[:, [\"human_scores\"]].rename(\n",
    "        columns={\"human_scores\": \"spearman_ru\"}\n",
    "    )\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "192ce4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0  bary  bertscore  bleu  chrf  meteor  rouge1  rougeL  sacrebleu  \\\nKendall_ro     1          0     8     2       3       5       4          6   \n\nUnnamed: 0  ter  \nKendall_ro    7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Unnamed: 0</th>\n      <th>bary</th>\n      <th>bertscore</th>\n      <th>bleu</th>\n      <th>chrf</th>\n      <th>meteor</th>\n      <th>rouge1</th>\n      <th>rougeL</th>\n      <th>sacrebleu</th>\n      <th>ter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Kendall_ro</th>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_kendall_ro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0  bary  bertscore  bleu  chrf  meteor  rouge1  rougeL  sacrebleu  \\\nPearson_ro     1          0     8     2       3       5       4          6   \n\nUnnamed: 0  ter  \nPearson_ro    7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Unnamed: 0</th>\n      <th>bary</th>\n      <th>bertscore</th>\n      <th>bleu</th>\n      <th>chrf</th>\n      <th>meteor</th>\n      <th>rouge1</th>\n      <th>rougeL</th>\n      <th>sacrebleu</th>\n      <th>ter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Pearson_ro</th>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_pearson_ro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "Unnamed: 0   bary  bertscore  bleu  chrf  meteor  rouge1  rougeL  sacrebleu  \\\nSpearman_ro     1          0     8     2       3       5       4          6   \n\nUnnamed: 0   ter  \nSpearman_ro    7  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Unnamed: 0</th>\n      <th>bary</th>\n      <th>bertscore</th>\n      <th>bleu</th>\n      <th>chrf</th>\n      <th>meteor</th>\n      <th>rouge1</th>\n      <th>rougeL</th>\n      <th>sacrebleu</th>\n      <th>ter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Spearman_ro</th>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_spearman_ro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8219049",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_scores = pd.concat(\n",
    "    [\n",
    "        ranking_kendall_cs,\n",
    "        ranking_kendall_de,\n",
    "        ranking_kendall_fi,\n",
    "        ranking_kendall_ro,\n",
    "        ranking_kendall_ru,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "pearson_scores = pd.concat(\n",
    "    [\n",
    "        ranking_pearson_cs,\n",
    "        ranking_pearson_de,\n",
    "        ranking_pearson_fi,\n",
    "        ranking_pearson_ro,\n",
    "        ranking_pearson_ru,\n",
    "    ],\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "\n",
    "spearman_scores = pd.concat(\n",
    "    [\n",
    "        ranking_spearman_cs,\n",
    "        ranking_spearman_de,\n",
    "        ranking_spearman_fi,\n",
    "        ranking_spearman_ro,\n",
    "        ranking_spearman_ru,\n",
    "    ],\n",
    "    axis=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eccf8b",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3a58319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kemeny consensus: 100%|██████████| 362880/362880 [00:44<00:00, 8142.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([array([1, 0, 8, 4, 3, 5, 2, 7, 6])], 0.2222222222222222)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemeny_consensus(spearman_scores.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "025b8fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kemeny consensus: 100%|██████████| 362880/362880 [00:44<00:00, 8172.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([array([1, 0, 8, 3, 4, 5, 2, 6, 7])], 0.2222222222222222)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemeny_consensus(pearson_scores.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0014bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Kemeny consensus: 100%|██████████| 362880/362880 [00:44<00:00, 8137.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "([array([1, 0, 8, 4, 3, 5, 2, 7, 6])], 0.3055555555555556)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kemeny_consensus(kendall_scores.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
