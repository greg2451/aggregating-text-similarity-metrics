{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6959a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import rankdata\n",
    "from itertools import permutations\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9010e26a",
   "metadata": {},
   "source": [
    "# Aggregating the results of different metrics (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe78b37",
   "metadata": {},
   "source": [
    "## Kameny consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610481f9",
   "metadata": {},
   "source": [
    "Each metrics will provide a ranking of different algorithms, that could be represented as a permutation of [1:N]. Insofar these rankings might be different according to the metrics, it is necessary to find a way to generate a new permutation that would be close to each of the permutations generated by the benchmark metrics. The first approach, called Kameny consensus, is based on a distance (the Kendall distance), that measures the dissimilarity between two permutations. \n",
    "Scipy as a module that computes a Kendall correlation (not to be confounded with a Kendall Tau distance).\n",
    "Our first goal is to code a function to evaluate the Kendall distance between two permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdd1561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=1.0, pvalue=0.3333333333333333)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendalltau([1, 2, 3], [1, 2, 3])\n",
    "# Not what we are looking for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f5f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_negative(n):\n",
    "    if n < 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def Kendall_distance(l1, l2):\n",
    "    if len(l1) != len(l2):\n",
    "        raise ValueError(\"Les permutations n'ont pas la mÃªme longueur\")\n",
    "    result = 0\n",
    "    for i in range(len(l1)):\n",
    "        for j in range(len(l1)):\n",
    "            result += is_negative((l1[i] - l1[j]) * (l2[i] - l2[j]))\n",
    "    normalization = len(l1) * (len(l1) - 1)\n",
    "    # normalization is made make the distance be in [0,1]\n",
    "    return result / normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeeb52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(Kendall_distance([0, 1, 2], [0, 1, 2]))\n",
    "print(Kendall_distance([0, 1, 2], [2, 1, 0]))\n",
    "print(Kendall_distance([0, 1, 2], [1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d44a018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kameny_consensus_step1(M, perm):\n",
    "    # M is an array in which M[i,j] is the ranking of algorithm i at test j\n",
    "    result = 0\n",
    "    for i in range(M.shape[0]):\n",
    "        result += Kendall_distance(perm, M[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "def Kameny_consensus(M):\n",
    "    L = []\n",
    "    dist = Kameny_consensus_step1(M, M[0])\n",
    "    perm = permutations(M[0])\n",
    "    for permutation in list(perm):\n",
    "        dist_travail = Kameny_consensus_step1(M, permutation)\n",
    "        if dist_travail < dist:\n",
    "            L = []\n",
    "            L += [np.array(permutation)]\n",
    "            dist = dist_travail\n",
    "        elif dist == dist_travail:\n",
    "            L += [np.array(permutation)]\n",
    "    return L, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d22d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.333333333333333\n",
      "1.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "M = np.array([[3, 2, 1, 0], [1, 2, 3, 0], [1, 3, 2, 0], [0, 1, 3, 2]])\n",
    "perm1 = [0, 1, 2, 3]\n",
    "print(Kameny_consensus_step1(M, perm1))\n",
    "perm2 = [3, 2, 1, 0]\n",
    "print(Kameny_consensus_step1(M, perm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc09d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([1, 3, 2, 0]), array([1, 2, 3, 0])], 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kameny_consensus(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe070ef",
   "metadata": {},
   "source": [
    "## First improvement of Kameny consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69cf74",
   "metadata": {},
   "source": [
    "All the rankings, given the different metrics have exactly the same weights. This might be a problem if we consider that some of the metrics are more relevant than others, or if some metrics are usually very close. So we can improve the Kameny consensus by giving a higher weight to metrics that are more relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b994fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Gameny_consensus_step1(M, perm, Weights):\n",
    "    # M is an array in which M[i,j] is the ranking of algorithm j at test i\n",
    "    # Weights[i] is the weight associated to test i\n",
    "    result = 0\n",
    "    for i in range(M.shape[0]):\n",
    "        result += Kendall_distance(perm, M[i]) * Weights[i]\n",
    "    return result\n",
    "\n",
    "\n",
    "def Weighted_Kameny_consensus(M, Weights):\n",
    "    L = []\n",
    "    dist = Weighted_Gameny_consensus_step1(M, M[0], Weights)\n",
    "    perm = permutations(M[0])\n",
    "    for permutation in list(perm):\n",
    "        dist_travail = Weighted_Gameny_consensus_step1(M, permutation, Weights)\n",
    "        if dist_travail < dist:\n",
    "            L = []\n",
    "            L += [np.array(permutation)]\n",
    "            dist = dist_travail\n",
    "        elif dist == dist_travail:\n",
    "            L += [np.array(permutation)]\n",
    "    return L, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0070ec32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([3, 2, 1, 0])], 0.16666666666666669)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weights = [0.7, 0.1, 0.1, 0.1]\n",
    "Weighted_Kameny_consensus(M, Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b80eb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_indexed_assignment(x):\n",
    "    result = np.empty(len(x), dtype=int)\n",
    "    temp = x.argsort()\n",
    "    result[temp] = np.arange(len(x))\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_ranking(df):\n",
    "    ranking = df\n",
    "    for col in df.columns:\n",
    "        ranking[col] = using_indexed_assignment(df[col])\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad40e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using_indexed_assignment(np.array([1, 5, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b883938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [[1.2, 1.7, 2], [2, 1.7, 1.2]],\n",
    "    index=[\"Algo1\", \"Algo2\"],\n",
    "    columns=[\"Test1\", \"Test2\", \"Test3\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "302b0aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = get_ranking(df).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "87dc29a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo1</th>\n",
       "      <th>Algo2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algo1  Algo2\n",
       "Test1      0      1\n",
       "Test2      0      1\n",
       "Test3      1      0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b09e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
